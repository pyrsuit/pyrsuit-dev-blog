[
    {
        "title": "When metrics eat your memory ğŸ§  ğŸ½ï¸",
        "date": "2025-07-24",
        "text": "Follow-up to my earlier post on Prometheus + Multiprocess Apps ... \n\n&nbsp;\n\nA few days in, I noticed the metrics directory was ballooning in memory ğŸˆ \n\n&nbsp;\n\nDigging in, I realized the Prometheus Python client (in multiprocess mode) writes separate files per metric per process. By default, those files are named things like `counter_12345.db`, where `12345` is the PID.\n\n&nbsp;\n\nSo when a `uWSGI` worker dies and gets replaced â€” totally normal behavior â€” the new process gets its own set of metric files. But the old files? They just stay there.\n\n&nbsp;\n\nSince the client doesnâ€™t automatically clean up stale files, the directory just keeps growing.\n\n&nbsp;\n\nâœ… Fix: I configured a cleanup step to remove metrics for dead processes.\n\n&nbsp;\n\nğŸ’¡ Takeaway: In multiprocess mode, the metrics client tracks data per PID. Without cleanup, these files accumulate and quietly consume memory â€” especially in environments with frequent process restarts."


    },

    {
        "title": "Goodbye temp venv hacks ğŸ‘‹",
        "date": "2025-07-19",
        "text": "Today I learned how much I enjoy using `uv` scripts for quick, one-off tasks.\n\n&nbsp;\n\nYou can define dependencies right at the top of the script, and when you run it with `uv`, it spins up a temporary virtual environment automatically. Once the script finishes, the environment is destroyed â€” super clean ğŸ§¹\n\n&nbsp;\n\nThis is perfect for things like initial tasks when starting a container, or scripts that import data, run a migration, or do any kind of setup that isn't needed once the main app is running.\n\n&nbsp;\n\nğŸ’¡ **Takeaway**: __[uv scripts](https://docs.astral.sh/uv/guides/scripts/)__ give you a disposable, isolated environment without any manual setup â€” ideal for clean, repeatable scripting without leaving a mess behind."
    },
    {
        "title": "Prometheus + Multiprocess Apps: A Lesson from the Trenches",
        "date": "2025-07-13",
        "text": "I recently deployed an API using `uWSGI` with multiple workers. I exposed a `/metrics` endpoint for `Prometheus` scraping â€” all looked good.\n\n&nbsp;\n\nUntil I realizedâ€¦ the metrics were off ğŸ« \n\n&nbsp;\n\nTurns out, when you're using multiple `uWSGI` workers, `Prometheus`' Python client needs **multiprocess mode** enabled to aggregate metrics across all worker processes. Without it, each process exposes its own separate metrics â€” so counters, for example, appear to jump up and down instead of increasing cumulatively across all workers. \n\n&nbsp;\n\nâœ… **Fix:** Configured __[multiprocess mode](https://prometheus.github.io/client_python/multiprocess/)__, so all workers write metrics to a shared directory.\n\n&nbsp;\n\nğŸ’¡ **Takeaway**: With multiple workers per replica, `Prometheus` scrapes the `/metrics` endpoint from only one worker per replica at random â€” so without multiprocess mode, your `Prometheus` metrics won't reflect the true state of your API â€” making it impossible to accurately track what's really happening."
    }
]